{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook should not be relaunched once you have the phrases.csv up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a **DataFrame** containing all phrases link to the company in each document, but also to add some features (when available) such as Title, Frequency and Count of company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_pandas\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import extract_text\n",
    "import text_summarization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JD_KDCREIT%20-%20Asset%20Mgt_Analyst_2017.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5f4c7c69049c32670176932fd1d305271372e912.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20100319_214216_BN4_F6859A6425BC8427482576EB00...</td>\n",
       "      <td>Keppel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>businessassociatelist--1-.xlsx</td>\n",
       "      <td>Keppel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WSHA2011%20Winners_8%20Aug.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           filename company\n",
       "0   0      JD_KDCREIT%20-%20Asset%20Mgt_Analyst_2017.pdf  Keppel\n",
       "1   1       5f4c7c69049c32670176932fd1d305271372e912.pdf  Keppel\n",
       "2   2  20100319_214216_BN4_F6859A6425BC8427482576EB00...  Keppel\n",
       "3   3                     businessassociatelist--1-.xlsx  Keppel\n",
       "4   4                     WSHA2011%20Winners_8%20Aug.pdf  Keppel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files = pd.read_csv(\"submission_mapper.csv\",delimiter=\"|\")\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>company</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JD_KDCREIT%20-%20Asset%20Mgt_Analyst_2017.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/JD_KDCREIT%20-%20Asset%20Mgt_Anal...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5f4c7c69049c32670176932fd1d305271372e912.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/5f4c7c69049c32670176932fd1d305271...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20100319_214216_BN4_F6859A6425BC8427482576EB00...</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/20100319_214216_BN4_F6859A6425BC8...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>businessassociatelist--1-.xlsx</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/businessassociatelist--1-.xlsx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WSHA2011%20Winners_8%20Aug.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/WSHA2011%20Winners_8%20Aug.pdf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           filename company  \\\n",
       "0   0      JD_KDCREIT%20-%20Asset%20Mgt_Analyst_2017.pdf  Keppel   \n",
       "1   1       5f4c7c69049c32670176932fd1d305271372e912.pdf  Keppel   \n",
       "2   2  20100319_214216_BN4_F6859A6425BC8427482576EB00...  Keppel   \n",
       "3   3                     businessassociatelist--1-.xlsx  Keppel   \n",
       "4   4                     WSHA2011%20Winners_8%20Aug.pdf  Keppel   \n",
       "\n",
       "                                           file_path  sentiment  \n",
       "0  files/Keppel/JD_KDCREIT%20-%20Asset%20Mgt_Anal...        NaN  \n",
       "1  files/Keppel/5f4c7c69049c32670176932fd1d305271...        NaN  \n",
       "2  files/Keppel/20100319_214216_BN4_F6859A6425BC8...        NaN  \n",
       "3        files/Keppel/businessassociatelist--1-.xlsx        NaN  \n",
       "4        files/Keppel/WSHA2011%20Winners_8%20Aug.pdf        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files['file_path'] = df_files.apply(lambda x : \"files/\"+x.company+\"/\"+x.filename,axis=1)\n",
    "#files.index = files['file_path']\n",
    "df_files['sentiment'] = np.nan\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sentences]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tqdm().pandas(desc=\"Progress:\")\n",
    "#phrases = pd.read_csv(\"Phrases.csv\")\n",
    "phrases = pd.DataFrame(data=[],columns=[\"Sentences\"])\n",
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keppelWord = ['keppel corporation', 'keppel capital', 'keppel reit', 'keppel infrastructure','keppel o&m', 'keppel energy', 'keppel offshore', 'keppel dhcs', 'keppel fairway', 'keppel professorship', 'keppel reit', 'keppel group', 'keppel land' , 'keppel singmarine', 'keppel fels', 'keppel shipyard','keppel shipyard' , 'keppel gas','keppel t&t', 'keppel bay', 'keppel telecom','keppel corp','keppel seghers','keppel center','keppel cebu','keppel thai','keppel philippines','keppel tatle','keppel  telecoms','keppel tower']\n",
    "prudentialWord = ['prudential mutual','prudential plc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doWeDrop(sentences):\n",
    "    isValid = False\n",
    "    for phrase in sentences:\n",
    "        lowered = phrase.lower()\n",
    "        #print(lowered)\n",
    "        for expr1 in keppelWord:\n",
    "            if(expr1 in lowered):\n",
    "                #print(\"valid\")\n",
    "                isValid = True\n",
    "        for expr2 in prudentialWord:\n",
    "            if(expr2 in lowered):\n",
    "                #print(\"valid\")\n",
    "                isValid = True\n",
    "        \n",
    "    return not isValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def fillSentences(path,company,fill):\n",
    "    print(path)\n",
    "    print(company)  \n",
    "    try:\n",
    "        text = extract_text.apply(path)\n",
    "        if doWeDrop(text):\n",
    "            return [\"-500\"]\n",
    "        important_sents = text_summarization.apply(text,company)\n",
    "        print(len(important_sents))\n",
    "        return important_sents\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        return [\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b98d0b46e2c4de0b9986bce64f4ccc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04bca7a216044b9b5deeff6ce0d8ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress:', max=387), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "already filled\n",
      "files/Prudential/complete_leaps_list.xls\n",
      "prudential\n",
      "Could not open Excel\n",
      "\n",
      "0\n",
      "files/Prudential/us-fsi-international-insurance-capital-standards.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/us-fsi-international-insurance-capital-standards.pdf\n",
      "0\n",
      "files/Prudential/Constitutional-Law-Manheim-2015.docx\n",
      "prudential\n",
      "0\n",
      "files/Prudential/AttendeeListing-DSM.xls\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/DFSA_AFN_AML_VER1.docx\n",
      "prudential\n",
      "0\n",
      "files/Prudential/GL.2014.192-life-dis.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/GL.2014.192-life-dis.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxpr\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\maxpr\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\maxpr\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "files/Prudential/2013523_prudentialprivilege.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/2013523_prudentialprivilege.pdf\n",
      "0\n",
      "files/Prudential/PrudentialULRepriced&Enhanced.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/PrudentialULRepriced&Enhanced.pdf\n",
      "0\n",
      "files/Prudential/0218177_Final_Business_Strategies_Planner.xlsx\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/2010-05-18e.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/2010-05-18e.pdf\n",
      "0\n",
      "files/Prudential/ACI%20Economic%20Sanctions%20DC%20-%20April%202016.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/ACI%20Economic%20Sanctions%20DC%20-%20April%202016.pdf\n",
      "0\n",
      "files/Prudential/finexam_rpt68241prudam.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/finexam_rpt68241prudam.pdf\n",
      "0\n",
      "files/Prudential/ocso-bomb_threat_samepage-brochure.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/ocso-bomb_threat_samepage-brochure.pdf\n",
      "0\n",
      "files/Prudential/M7%20C3%20b%20ANG.docx\n",
      "prudential\n",
      "0\n",
      "files/Prudential/Agenda%20Jan%2022.doc\n",
      "prudential\n",
      "error\n",
      "files/Prudential/icici_comman_sip_stp_swp_dtp_sip_PLUS_WITH_FATCA_FORM.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/icici_comman_sip_stp_swp_dtp_sip_PLUS_WITH_FATCA_FORM.pdf\n",
      "0\n",
      "files/Prudential/ppr_pros_3.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/ppr_pros_3.pdf\n",
      "0\n",
      "files/Prudential/Carter-Strategic-Recruitment.xlsx\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/attendees-as-of-10.xls\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/Companies-issued-with-Permits-2015.xlsx\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/Annex_2.doc\n",
      "prudential\n",
      "error\n",
      "files/Prudential/pru-165-1512.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/pru-165-1512.pdf\n",
      "0\n",
      "files/Prudential/YOU%20DECIDE%20-%20STUDY%20SITE_1.doc\n",
      "prudential\n",
      "error\n",
      "files/Prudential/Annual_Report_2011.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/Annual_Report_2011.pdf\n",
      "0\n",
      "files/Prudential/pillar-3_prtwp010.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/pillar-3_prtwp010.pdf\n",
      "0\n",
      "files/Prudential/2013_04.xls\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/analyst_epcrs-rps-2016_51_0517.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/analyst_epcrs-rps-2016_51_0517.pdf\n",
      "0\n",
      "files/Prudential/c11-attendeelist-public.xls\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/New401k_457InvestmentOption.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/New401k_457InvestmentOption.pdf\n",
      "0\n",
      "files/Prudential/Annex%20XI-Instruction-Guide-for-Completing-the-Data-Collection-Template.docx\n",
      "prudential\n",
      "0\n",
      "files/Prudential/W020170524853108200162.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/W020170524853108200162.pdf\n",
      "0\n",
      "files/Prudential/nfa_list.xls\n",
      "prudential\n",
      "Could not open Excel\n",
      "error\n",
      "files/Prudential/IPBF10299.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/IPBF10299.pdf\n",
      "0\n",
      "files/Prudential/51945_BGL_OGL_Retirees_Ed_06-2015,2.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/51945_BGL_OGL_Retirees_Ed_06-2015,2.pdf\n",
      "0\n",
      "files/Prudential/Prudential_C2S.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/Prudential_C2S.pdf\n",
      "0\n",
      "files/Prudential/PensAnalyst_final415regs_DB.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/PensAnalyst_final415regs_DB.pdf\n",
      "0\n",
      "files/Prudential/IPBB10147.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/IPBB10147.pdf\n",
      "0\n",
      "files/Prudential/gsp2014.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/gsp2014.pdf\n",
      "0\n",
      "files/Prudential/fourteen.docx\n",
      "prudential\n",
      "0\n",
      "files/Prudential/2015-sustainability-infographic-for-website.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/2015-sustainability-infographic-for-website.pdf\n",
      "0\n",
      "files/Prudential/PruLicensing.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/PruLicensing.pdf\n",
      "0\n",
      "files/Prudential/SP%20Annuity%20One%20Prospectus.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/SP%20Annuity%20One%20Prospectus.pdf\n",
      "0\n",
      "files/Prudential/avrupa_birligi_bakanliginda_mevcut_olan_ab_mevzuati_cevirilerine_iliskin_envanter_tablosu.xlsx\n",
      "prudential\n",
      "Could not open Excel\n",
      "0\n",
      "files/Prudential/PRIAC_GA_Report.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/PRIAC_GA_Report.pdf\n",
      "0\n",
      "files/Prudential/ORD_112175.pdf\n",
      "prudential\n",
      "Could not parse the PDF,  files/Prudential/ORD_112175.pdf\n"
     ]
    }
   ],
   "source": [
    "##Dont't relaunch this it is used to fill the DF\n",
    "tqdm().pandas(desc=\"Progress:\")\n",
    "df_files['sentences'] = \"\"\n",
    "phrases[\"Sentences\"] = df_files.progress_apply(lambda row : fillSentences(row[\"file_path\"],row[\"company\"].lower(),row[\"sentences\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>[, important that you review the form for comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "      <td>[, \\nan entity required under Section 352 of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>[The Grasshopper Company 916019.0 OH 41838.0 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>361</td>\n",
       "      <td>[, , Philadelphia, PA 19176 \\nTel 800-524-0542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>362</td>\n",
       "      <td>[the fruits of an attorney’s trial preparation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>363</td>\n",
       "      <td>363</td>\n",
       "      <td>[,   \\n \\n©201\\n2\\n \\nPrudential \\nFinancial, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "      <td>[400070.0 tpafauziyakurla@gmail.com 022 250340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>[Read, and note the  definitions  contained  i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>366</td>\n",
       "      <td>366</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>367</td>\n",
       "      <td>[CASUALTY INSURERS ASSN OF AMERICA- AMENDMENT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>[credit reporting plays in promoting financial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>369</td>\n",
       "      <td>[, New York, where it is issued by Pruco \\nLif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>[, 28, 2002, and still qualify for the prototy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>[Project \\nand \\nprospects for\\n a covered agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>[NFI\\n-\\nODCE Preliminary, 12\\n-\\nOct\\n-\\n2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>373</td>\n",
       "      <td>[LLP\\n davispolk.com\\n  VISUAL SUMMARY\\n Forei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>374</td>\n",
       "      <td>374</td>\n",
       "      <td>[, 800) 225-1852Please print clearly, preferab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>375</td>\n",
       "      <td>[details of the exam. This is an electronic fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>376</td>\n",
       "      <td>376</td>\n",
       "      <td>[William Acebo Assurant Miami FL \\nBailey Acev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>377</td>\n",
       "      <td>377</td>\n",
       "      <td>[, on the Transition to Prudential RetirementT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "      <td>[,  Farmers  New  World  Life,  Massachusetts\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>[, ,  THE ˜˚˛˝ PRUDENTIAL PRODUCTIVITY \\nAWARD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>[150,000,000 France                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>381</td>\n",
       "      <td>381</td>\n",
       "      <td>[Phoenix ARC Private Limited\\nJM Financial Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>382</td>\n",
       "      <td>[opposition  to  such  fee  application  withi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>[_______________  To:\\n  The Prudential Assura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>[, of the Insurance Act 1978, makes the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>385</td>\n",
       "      <td>[Post Holdings, Inc. 5825000.0 5766750.0 6.0 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>[Members of the SIG Op\\nerational Risk Subgrou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1  \\\n",
       "0             0             0   \n",
       "1             1             1   \n",
       "2             2             2   \n",
       "3             3             3   \n",
       "4             4             4   \n",
       "5             5             5   \n",
       "6             6             6   \n",
       "7             7             7   \n",
       "8             8             8   \n",
       "9             9             9   \n",
       "10           10            10   \n",
       "11           11            11   \n",
       "12           12            12   \n",
       "13           13            13   \n",
       "14           14            14   \n",
       "15           15            15   \n",
       "16           16            16   \n",
       "17           17            17   \n",
       "18           18            18   \n",
       "19           19            19   \n",
       "20           20            20   \n",
       "21           21            21   \n",
       "22           22            22   \n",
       "23           23            23   \n",
       "24           24            24   \n",
       "25           25            25   \n",
       "26           26            26   \n",
       "27           27            27   \n",
       "28           28            28   \n",
       "29           29            29   \n",
       "..          ...           ...   \n",
       "357         357           357   \n",
       "358         358           358   \n",
       "359         359           359   \n",
       "360         360           360   \n",
       "361         361           361   \n",
       "362         362           362   \n",
       "363         363           363   \n",
       "364         364           364   \n",
       "365         365           365   \n",
       "366         366           366   \n",
       "367         367           367   \n",
       "368         368           368   \n",
       "369         369           369   \n",
       "370         370           370   \n",
       "371         371           371   \n",
       "372         372           372   \n",
       "373         373           373   \n",
       "374         374           374   \n",
       "375         375           375   \n",
       "376         376           376   \n",
       "377         377           377   \n",
       "378         378           378   \n",
       "379         379           379   \n",
       "380         380           380   \n",
       "381         381           381   \n",
       "382         382           382   \n",
       "383         383           383   \n",
       "384         384           384   \n",
       "385         385           385   \n",
       "386         386           386   \n",
       "\n",
       "                                             Sentences  \n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12                                                      \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                                      \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "25                                                      \n",
       "26                                                      \n",
       "27                                                      \n",
       "28                                                      \n",
       "29                                                      \n",
       "..                                                 ...  \n",
       "357                                                 []  \n",
       "358  [, important that you review the form for comp...  \n",
       "359  [, \\nan entity required under Section 352 of t...  \n",
       "360  [The Grasshopper Company 916019.0 OH 41838.0 4...  \n",
       "361  [, , Philadelphia, PA 19176 \\nTel 800-524-0542...  \n",
       "362  [the fruits of an attorney’s trial preparation...  \n",
       "363  [,   \\n \\n©201\\n2\\n \\nPrudential \\nFinancial, ...  \n",
       "364  [400070.0 tpafauziyakurla@gmail.com 022 250340...  \n",
       "365  [Read, and note the  definitions  contained  i...  \n",
       "366                                                 []  \n",
       "367  [CASUALTY INSURERS ASSN OF AMERICA- AMENDMENT ...  \n",
       "368  [credit reporting plays in promoting financial...  \n",
       "369  [, New York, where it is issued by Pruco \\nLif...  \n",
       "370  [, 28, 2002, and still qualify for the prototy...  \n",
       "371  [Project \\nand \\nprospects for\\n a covered agr...  \n",
       "372  [NFI\\n-\\nODCE Preliminary, 12\\n-\\nOct\\n-\\n2015...  \n",
       "373  [LLP\\n davispolk.com\\n  VISUAL SUMMARY\\n Forei...  \n",
       "374  [, 800) 225-1852Please print clearly, preferab...  \n",
       "375  [details of the exam. This is an electronic fo...  \n",
       "376  [William Acebo Assurant Miami FL \\nBailey Acev...  \n",
       "377  [, on the Transition to Prudential RetirementT...  \n",
       "378  [,  Farmers  New  World  Life,  Massachusetts\\...  \n",
       "379  [, ,  THE ˜˚˛˝ PRUDENTIAL PRODUCTIVITY \\nAWARD...  \n",
       "380  [150,000,000 France                           ...  \n",
       "381  [Phoenix ARC Private Limited\\nJM Financial Ass...  \n",
       "382  [opposition  to  such  fee  application  withi...  \n",
       "383  [_______________  To:\\n  The Prudential Assura...  \n",
       "384  [, of the Insurance Act 1978, makes the follow...  \n",
       "385  [Post Holdings, Inc. 5825000.0 5766750.0 6.0 4...  \n",
       "386  [Members of the SIG Op\\nerational Risk Subgrou...  \n",
       "\n",
       "[387 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save\n",
    "#phrases.to_csv(\"Phrases.csv\")\n",
    "#type(phrases.Sentences[0][1])\n",
    "#test = pd.read_csv(\"Phrases.csv\")\n",
    "#testing = test.head(193)\n",
    "#df_files_new = df_files\n",
    "#for i in range(len(testing.Sentences)):\n",
    "#    df_files_new.loc[i,'sentences'] = testing.Sentences[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_files_new.to_csv(\"df_file_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (62, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (61, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (3, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (6, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (9, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (12, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (15, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (21, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (24, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (27, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (30, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (33, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (36, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (39, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (42, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (45, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (48, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (51, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (54, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (57, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (60, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (63, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (66, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (69, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (72, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (75, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (78, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (81, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (84, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (87, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (91, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (92, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (94, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (95, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (74, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (73, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (16, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (230, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (231, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (232, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (233, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (234, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (237, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (238, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (514, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (515, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (516, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (513, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4346, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4347, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4349, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4345, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4335, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4336, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4340, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4339, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4338, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4337, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4341, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4342, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4344, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4343, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4351, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4348, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (4350, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2445, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2454, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2456, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2451, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2457, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2453, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2447, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2448, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2449, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2452, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2455, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2450, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2444, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2443, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2442, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2446, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2458, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (2459, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: unknown compression method (102, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (101, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (24, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (34, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (36, 0)\n",
      "[ERROR] uncompress.py:80 Error -3 while decompressing data: incorrect header check (37, 0)\n"
     ]
    }
   ],
   "source": [
    "df_files_new['title'] = df_files.apply(lambda row : extract_text.extract_title(row['file_path']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>company</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentences</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JD_KDCREIT%20-%20Asset%20Mgt_Analyst_2017.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/JD_KDCREIT%20-%20Asset%20Mgt_Anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', '', 'is a premier asset manager in Asia. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5f4c7c69049c32670176932fd1d305271372e912.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/5f4c7c69049c32670176932fd1d305271...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['TP is lifted to \\nS$6.00 as we roll over val...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20100319_214216_BN4_F6859A6425BC8427482576EB00...</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/20100319_214216_BN4_F6859A6425BC8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['', '. \\n\\n \\n19 March 2010, Baku, Azerbaijan...</td>\n",
       "      <td>(Microsoft Word - SOCARKEPPEL.doc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>businessassociatelist--1-.xlsx</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/businessassociatelist--1-.xlsx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WSHA2011%20Winners_8%20Aug.pdf</td>\n",
       "      <td>Keppel</td>\n",
       "      <td>files/Keppel/WSHA2011%20Winners_8%20Aug.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['/o Servoo Apportorai \\n(Tiong Seng Contracto...</td>\n",
       "      <td>(Microsoft Word - WSHA2011 Winners_190711.doc)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           filename company  \\\n",
       "0   0      JD_KDCREIT%20-%20Asset%20Mgt_Analyst_2017.pdf  Keppel   \n",
       "1   1       5f4c7c69049c32670176932fd1d305271372e912.pdf  Keppel   \n",
       "2   2  20100319_214216_BN4_F6859A6425BC8427482576EB00...  Keppel   \n",
       "3   3                     businessassociatelist--1-.xlsx  Keppel   \n",
       "4   4                     WSHA2011%20Winners_8%20Aug.pdf  Keppel   \n",
       "\n",
       "                                           file_path  sentiment  \\\n",
       "0  files/Keppel/JD_KDCREIT%20-%20Asset%20Mgt_Anal...        NaN   \n",
       "1  files/Keppel/5f4c7c69049c32670176932fd1d305271...        NaN   \n",
       "2  files/Keppel/20100319_214216_BN4_F6859A6425BC8...        NaN   \n",
       "3        files/Keppel/businessassociatelist--1-.xlsx        NaN   \n",
       "4        files/Keppel/WSHA2011%20Winners_8%20Aug.pdf        NaN   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  ['', '', 'is a premier asset manager in Asia. ...   \n",
       "1  ['TP is lifted to \\nS$6.00 as we roll over val...   \n",
       "2  ['', '. \\n\\n \\n19 March 2010, Baku, Azerbaijan...   \n",
       "3                                                 []   \n",
       "4  ['/o Servoo Apportorai \\n(Tiong Seng Contracto...   \n",
       "\n",
       "                                            title  \n",
       "0                                            None  \n",
       "1                                              ()  \n",
       "2              (Microsoft Word - SOCARKEPPEL.doc)  \n",
       "3                                                  \n",
       "4  (Microsoft Word - WSHA2011 Winners_190711.doc)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_files_new.to_csv(\"df_file_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not open Excel\n",
      "Could not parse the PDF,  files/Keppel/keppel_wickens_design_and_analysis.pdf\n",
      "Could not parse the PDF,  files/Keppel/54214cdb0cf2ce3a91b6e2bd.pdf\n",
      "Could not open Excel\n",
      "Could not open Excel\n",
      "Could not open Excel\n",
      "Could not parse the PDF,  files/Prudential/10.1007%2Fs10551-010-0597-8.pdf\n",
      "Could not open Excel\n",
      "Could not parse the PDF,  files/Keppel/keppel_wickens_design_and_analysis.pdf\n",
      "Could not parse the PDF,  files/Keppel/54214cdb0cf2ce3a91b6e2bd.pdf\n",
      "Could not open Excel\n",
      "Could not open Excel\n",
      "Could not open Excel\n",
      "Could not parse the PDF,  files/Prudential/10.1007%2Fs10551-010-0597-8.pdf\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "(\"Package not found at 'files/Prudential/2017091217070118828.docx'\", 'occurred at index 340')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-16f9a3890f69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_files_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'occurence'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_occurence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4875\u001b[0m                         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4876\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4877\u001b[1;33m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[0;32m   4878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4879\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4971\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4972\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4973\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4974\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4975\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-16f9a3890f69>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_files_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'occurence'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_occurence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\KaggleDathena\\extract_text.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mexctract_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'WORD'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mexctract_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\KaggleDathena\\extract_text.py\u001b[0m in \u001b[0;36mexctract_word\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mfullText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpara\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\docx\\api.py\u001b[0m in \u001b[0;36mDocument\u001b[1;34m(docx)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \"\"\"\n\u001b[0;32m     24\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mdocument_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\docx\\opc\\package.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mpkg_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\docx\\opc\\pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(pkg_file)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m|\u001b[0m\u001b[0mPackageReader\u001b[0m\u001b[1;33m|\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mloaded\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mphys_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\docx\\opc\\phys_pkg.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 raise PackageNotFoundError(\n\u001b[1;32m---> 31\u001b[1;33m                     \u001b[1;34m\"Package not found at '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 )\n\u001b[0;32m     33\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# assume it's a stream and pass it to Zip reader to sort out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: (\"Package not found at 'files/Prudential/2017091217070118828.docx'\", 'occurred at index 340')"
     ]
    }
   ],
   "source": [
    "df_files_new['occurence'] = df_files.apply(lambda row : extract_text.count_occurence(extract_text.apply(row['file_path']),row['company']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_files_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_files_new['freq'] = df_files.apply(lambda row : extract_text.frequency_occurence(extract_text.apply(row['file_path']),row['company']),axis=1)\n",
    "\n",
    "df_files_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_files_new.to_csv(\"df_file_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"df_file_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
